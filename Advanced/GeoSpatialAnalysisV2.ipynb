{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Install java\n",
    "#! sudo apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/conda/lib/python3.7/site-packages/pyspark/\"\n",
    "os.environ[\"PATH\"] = os.environ[\"SPARK_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "os.environ[\"geospark.global.charset\"]=\"utf8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.sql.functions import from_unixtime\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import col, to_timestamp,date_format\n",
    "from pyspark import StorageLevel\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import (Tokenizer, Normalizer,LemmatizerModel, StopWordsCleaner)\n",
    "from pyspark.ml import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark import StorageLevel\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import LongType\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from geospark.register import GeoSparkRegistrator\n",
    "from geospark.register import upload_jars\n",
    "from geospark.core.SpatialRDD import SpatialRDD\n",
    "from geospark.core.SpatialRDD import PointRDD\n",
    "from geospark.core.SpatialRDD import PolygonRDD\n",
    "from geospark.core.SpatialRDD import LineStringRDD\n",
    "from geospark.core.enums import FileDataSplitter\n",
    "from geospark.utils.adapter import Adapter\n",
    "from geospark.core.spatialOperator import KNNQuery\n",
    "from geospark.core.spatialOperator import JoinQuery\n",
    "from geospark.core.spatialOperator import RangeQuery\n",
    "from geospark.core.formatMapper.shapefileParser import ShapefileReader\n",
    "from geospark.core.formatMapper import WkbReader\n",
    "from geospark.core.formatMapper import WktReader\n",
    "from geospark.core.formatMapper import GeoJsonReader\n",
    "from geospark.sql.types import GeometryType\n",
    "from geospark.core.enums import GridType\n",
    "from geospark.core.SpatialRDD import RectangleRDD\n",
    "from geospark.core.enums import IndexType\n",
    "from geospark.core.geom.envelope import Envelope\n",
    "from geospark.utils import GeoSparkKryoRegistrator, KryoSerializer\n",
    "\n",
    "def start():\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark-Geo-Spatial\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"24G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryo.registrator\", GeoSparkKryoRegistrator.getName) \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2040M\") \\\n",
    "        .config(\"geospark.global.charset\", \"utf8\")\n",
    "    return builder.getOrCreate()\n",
    "spark = start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeoSparkRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_jars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "geo_json_rdd = GeoJsonReader.readToGeometryRDD(spark.sparkContext, \"outbreak1.geojson\",False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = geo_json_rdd.toPandas()\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "gdf.plot(\n",
    "    figsize=(10, 8),\n",
    "    column=\"value\",\n",
    "    legend=True,\n",
    "    cmap='YlOrBr',\n",
    "    scheme='quantiles',\n",
    "    edgecolor='lightgray'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Adapter.toDf(geo_json_rdd, spark).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
